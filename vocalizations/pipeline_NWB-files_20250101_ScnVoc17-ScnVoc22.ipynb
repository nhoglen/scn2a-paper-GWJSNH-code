{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0fb490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "from uuid import uuid4\n",
    "from dateutil.tz import tzlocal\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import librosa\n",
    "import pickle\n",
    "\n",
    "from pynwb import NWBHDF5IO, NWBFile, TimeSeries\n",
    "from pynwb.file import Subject\n",
    "from pynwb.behavior import (\n",
    "    BehavioralEpochs,\n",
    "    BehavioralEvents,\n",
    "    BehavioralTimeSeries,\n",
    "    CompassDirection,\n",
    "    EyeTracking,\n",
    "    Position,\n",
    "    PupilTracking,\n",
    "    SpatialSeries,\n",
    ")\n",
    "from pynwb.epoch import TimeIntervals\n",
    "from pynwb.image import ImageSeries\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import wave\n",
    "\n",
    "from ndx_manoli_meta import AssayMetadata\n",
    "from nwb_utils import *\n",
    "from vak_utils import *\n",
    "from frequency_stats_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c4a38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- USER PARAMETERS -----\n",
    "# NWB metadata\n",
    "cohort_tag = 'ScnVoc'\n",
    "GT = 'Scn2a'\n",
    "sdate = date(2024,3,14) #20240314\n",
    "session_description = f'Vocal recordings from cohort: {cohort_tag} with genotype: {GT} starting on date: {sdate}.'\n",
    "lab='Manoli @ UCSF'\n",
    "\n",
    "# snippet windowing parameters\n",
    "winlen = 2\n",
    "overlap = 0.25\n",
    "\n",
    "# set parameters for making toml files\n",
    "defaults_fname = 'vak_defaults.pkl' # move this to a central location\n",
    "# toml_name = f'{this_rec}-predict.toml'\n",
    "\n",
    "# set parameters for pretending annotations are full boxes\n",
    "minfreq = 15000\n",
    "maxfreq = 65000\n",
    "\n",
    "# set up pathing\n",
    "rootpath = 'M:\\\\scn2a-paper-GWJSNH'\n",
    "nwbfile_path = os.path.join(rootpath,f'{cohort_tag}_nwb')\n",
    "analysis_path = os.path.join(rootpath,f'{cohort_tag}_analysis')\n",
    "acq_path = os.path.join(rootpath,f'{cohort_tag}_acquisition')\n",
    "pred_path = os.path.join(rootpath,f'{cohort_tag}_predictions')\n",
    "paths = [nwbfile_path,analysis_path,acq_path,pred_path]\n",
    "for pathi in paths:\n",
    "    if not os.path.isdir(pathi):\n",
    "        os.makedirs(pathi)\n",
    "        \n",
    "# load up stored defaults for writing toml files\n",
    "defaults_file = open(os.path.join('M:\\\\vocalizations','vak_defaults.pkl'),'rb')\n",
    "defaults = pickle.load(defaults_file)\n",
    "\n",
    "# set up metadata table\n",
    "# metafile = f'metadata_{cohort_tag}.csv'\n",
    "metafile = 'metadata_ScnVoc_20250101.csv'\n",
    "\n",
    "# -------- frequency calculation parameters ----------\n",
    "# times for start and end pad of the snippets\n",
    "spad = 0 # in seconds\n",
    "epad = 0\n",
    "\n",
    "# parameters for Welch PSD\n",
    "NFFT = 512\n",
    "noverl = 400\n",
    "pad = 0.05\n",
    "cmap = 'jet'\n",
    "cmin = -60\n",
    "cmax = 30\n",
    "n_mfcc = 256\n",
    "n_mels = n_mfcc\n",
    "fmin = 20000\n",
    "fmax = 80000\n",
    "psdwin = 'hann'\n",
    "\n",
    "# parameters for mel spec\n",
    "mel_nfft = 1024\n",
    "mel_winlen = 900\n",
    "\n",
    "# false positive thresholding\n",
    "pwrmin = 0.9\n",
    "\n",
    "# peak identification parameters\n",
    "rel_height_param = 0.98 # point on the peak at which to calculate the bandwidth\n",
    "stdmx = 1\n",
    "prominence_factor = 2.5 # used to calculate how high frequency peaks need to be\n",
    "\n",
    "# contour thresholding parameters\n",
    "thresh = 0.25\n",
    "grndmeanfac = 1.5\n",
    "\n",
    "# spectrogram smooothing parameters\n",
    "wiener_kernel = (4, 4)\n",
    "\n",
    "# contour fit smoothing parameters\n",
    "lowess = sm.nonparametric.lowess\n",
    "fr=0.2\n",
    "it=4\n",
    "\n",
    "# mel frequencies\n",
    "mf = librosa.mel_frequencies(n_mels=n_mels, fmin=fmin, fmax=fmax)\n",
    "\n",
    "# names and descriptions of stats, in order\n",
    "allstats = ['callBool','startTime','duration','f0','numberFreqBands','numberPeaks','startFreq','endFreq','minFreq','maxFreq','absMinFreq',\n",
    "           'absMaxFreq','sinuosity','timeToMaxPower','frequencyAtMaxPower','totalContourLength']\n",
    "descriptions = ['use call: true for include in analysis, false for false positive',\n",
    "               'time of call start',\n",
    "               'duration of call in s',\n",
    "               'peak frequency of lowest frequency band identified by Welch PSD',\n",
    "               'number of frequency peaks identified from Welch PSD',\n",
    "               'number of peaks identified in contours',\n",
    "               'number of signal peaks identified in contours',\n",
    "               'frequency at beginning of longest contour',\n",
    "               'frequency at end of longest contour',\n",
    "               'lowest contour frequency reached in longest contour',\n",
    "               'highest contour frequency reached in longest contour',\n",
    "               'lowest contour frequency reached in call',\n",
    "               'highest contour frequency reached in call',\n",
    "               'sinuosity of longest contour',\n",
    "               'time into call of highest power in s',\n",
    "               'frequency at max power in Hz',\n",
    "               'total number of bins with above threshold contour',]\n",
    "\n",
    "# which call time data to use from the NWB file\n",
    "use_annos = 'calls_vak_merge_5ms' # corresponds to all merged calls but not adjusted for time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ce5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Generate metadata object based on metadata read in from table -----\n",
    "\n",
    "def make_metadata_object(atype,excl,dur,room,timeline,etho,exp,timeline_comp,\n",
    "                         colors,pID,pGT,dpostpair,sID=None,sGT=None,lane=None,chamber=None):\n",
    "        \n",
    "    match atype:\n",
    "        case 'introduction':\n",
    "            metaObj = AssayMetadata(\n",
    "                assay_type=atype,\n",
    "                exclude_flag=excl,\n",
    "                duration=dur,\n",
    "                room=room,\n",
    "                timeline=timeline,\n",
    "                ethogram=etho,\n",
    "#                 experimenter=exp,\n",
    "                timeline_complete=timeline_comp,\n",
    "                colors=colors,\n",
    "                assay_type__partner_ID=pID,\n",
    "                assay_type__partner_GT=pGT,\n",
    "                assay_type__description='Standard introduction (vocal series).',\n",
    "                assay_type__days_post_pairing=dpostpair,\n",
    "                assay_type__divided=False,            \n",
    "            )\n",
    "            \n",
    "        case 'divided':\n",
    "            metaObj = AssayMetadata(\n",
    "                assay_type=atype,\n",
    "                exclude_flag=excl,\n",
    "                duration=dur,\n",
    "                room=room,\n",
    "                timeline=timeline,\n",
    "                ethogram=etho,\n",
    "                experimenter=exp,\n",
    "                timeline_complete=timeline_comp,\n",
    "                colors=colors,\n",
    "                assay_type__partner_ID=pID,\n",
    "                assay_type__partner_GT=pGT,\n",
    "                assay_type__description='Vocal recording in home cage with animals separated by a barrier.',\n",
    "                assay_type__days_post_pairing=dpostpair,\n",
    "                assay_type__divided=True,            \n",
    "            )\n",
    "            \n",
    "        case 'mating':\n",
    "            metaObj = AssayMetadata(\n",
    "                assay_type=atype,\n",
    "                exclude_flag=excl,\n",
    "                duration=dur,\n",
    "                room=room,\n",
    "                timeline=timeline,\n",
    "                ethogram=etho,\n",
    "                experimenter=exp,\n",
    "                timeline_complete=timeline_comp,\n",
    "                colors=colors,\n",
    "                assay_type__partner_ID=pID,\n",
    "                assay_type__partner_GT=pGT,\n",
    "                assay_type__description='Standard timed mating (vocal series).',\n",
    "                assay_type__days_post_pairing=dpostpair,\n",
    "                assay_type__divided=False,                   \n",
    "            )\n",
    "            \n",
    "        case 'finteract1':\n",
    "            metaObj = AssayMetadata(\n",
    "                assay_type=atype,\n",
    "                exclude_flag=excl,\n",
    "                duration=dur,\n",
    "                room=room,\n",
    "                timeline=timeline,\n",
    "                ethogram=etho,\n",
    "                experimenter=exp,\n",
    "                timeline_complete=timeline_comp,\n",
    "                colors=colors,\n",
    "                assay_type__partner_ID=pID,\n",
    "                assay_type__partner_GT=pGT,\n",
    "                assay_type__description='Vocal recording in home cage with animals freely interacting.',\n",
    "                assay_type__days_post_pairing=dpostpair,\n",
    "                assay_type__divided=False,                   \n",
    "            )\n",
    "            \n",
    "        case 'finteract2':\n",
    "            metaObj = AssayMetadata(\n",
    "                assay_type=atype,\n",
    "                exclude_flag=excl,\n",
    "                duration=dur,\n",
    "                room=room,\n",
    "                timeline=timeline,\n",
    "                ethogram=etho,\n",
    "                experimenter=exp,\n",
    "                timeline_complete=timeline_comp,\n",
    "                colors=colors,\n",
    "                assay_type__partner_ID=pID,\n",
    "                assay_type__partner_GT=pGT,\n",
    "                assay_type__description='Vocal recording in home cage with animals freely interacting.',\n",
    "                assay_type__days_post_pairing=dpostpair,\n",
    "                assay_type__divided=False,               \n",
    "            )\n",
    "            \n",
    "        case 'dividerhalf':\n",
    "            metaObj = AssayMetadata(\n",
    "                assay_type=atype,\n",
    "                exclude_flag=excl,\n",
    "                duration=dur,\n",
    "                room=room,\n",
    "                timeline=timeline,\n",
    "                ethogram=etho,\n",
    "                experimenter=exp,\n",
    "                timeline_complete=timeline_comp,\n",
    "                colors=colors,\n",
    "                assay_type__partner_ID=pID,\n",
    "                assay_type__partner_GT=pGT,\n",
    "                assay_type__description='Vocal recording in home cage with animals divided for 15 mins then freely interacting for 15 mins.',\n",
    "                assay_type__days_post_pairing=dpostpair,\n",
    "                assay_type__divided=True,             \n",
    "            )\n",
    "            \n",
    "        case 'PPT':\n",
    "            metaObj = AssayMetadata(\n",
    "                assay_type=atype,\n",
    "                exclude_flag=excl,\n",
    "                duration=dur,\n",
    "                room=room,\n",
    "                timeline=timeline,\n",
    "                ethogram=etho,\n",
    "                experimenter=exp,\n",
    "                timeline_complete=timeline_comp,\n",
    "                colors=colors,\n",
    "                assay_type__partner_ID=pID,\n",
    "                assay_type__partner_GT=pGT,\n",
    "                assay_type__description='Standard PPT (vocal series).',\n",
    "                assay_type__days_post_pairing=dpostpair,\n",
    "                assay_type__divided=False,\n",
    "                assay_type__stranger_ID=sID,\n",
    "                assay_type__stranger_GT=sGT,\n",
    "                assay_type__PPT_lane=lane,\n",
    "                assay_type__partner_chamber=chamber,\n",
    "            )\n",
    "            \n",
    "    return metaObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74fd3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScnVoc17_introduction.nwb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nerissa\\anaconda3\\envs\\voc230824\\lib\\site-packages\\hdmf\\build\\objectmapper.py:260: DtypeConversionWarning: Spec 'vole_metadata/colors': Value with data type int32 is being converted to data type float32 as specified.\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScnVoc18_introduction.nwb\n",
      "ScnVoc19_introduction.nwb\n",
      "ScnVoc20_introduction.nwb\n",
      "ScnVoc21_introduction.nwb\n",
      "ScnVoc22_introduction.nwb\n"
     ]
    }
   ],
   "source": [
    "# ----- Loop over metadata table and write files -----\n",
    "\n",
    "# whether to write NWB files to disk yet\n",
    "write_NWB_to_disk = True\n",
    "\n",
    "# load metadata\n",
    "meta = pd.read_csv(os.path.join(analysis_path,metafile),sep=',')\n",
    "meta.FocalColor = meta.FocalColor.apply(literal_eval) # convert the colors to real arrays\n",
    "\n",
    "# -- loop over metadata\n",
    "for i, ptag in enumerate(meta.PairTag):\n",
    "    assay_type = meta.AssayType[i]\n",
    "    nwbfilename = f'{ptag}_{assay_type}.nwb'\n",
    "    print(nwbfilename)\n",
    "    \n",
    "    # check if file already exists\n",
    "    wfullpath = os.path.join(nwbfile_path,nwbfilename)    \n",
    "    if not os.path.exists(wfullpath):    \n",
    "        \n",
    "        # get session specific metadata\n",
    "        thisdate = str(meta.RecDate[i])\n",
    "        pairdate = str(meta.PairDate[i])\n",
    "\n",
    "        # set up recording time... it would be nice to get actual video data for the times\n",
    "        datepieces = get_date_from_block(thisdate)\n",
    "        rtime = meta.RecTime[i]\n",
    "        timepieces = rtime.split(':')\n",
    "        sess_start = datetime(datepieces[0],datepieces[1],datepieces[2],int(timepieces[0]),int(timepieces[1]),0,0,tzlocal())\n",
    "\n",
    "        session_description = f'Vocal annotations from pair {ptag} in a(n) {assay_type} assay.'\n",
    "        \n",
    "        # calculate days post pairing\n",
    "        rdate = date(int(thisdate[0:4]),int(thisdate[4:6]),int(thisdate[6:]))\n",
    "        pdate = date(int(pairdate[0:4]),int(pairdate[4:6]),int(pairdate[6:]))\n",
    "        dpp = rdate-pdate\n",
    "\n",
    "        # make NWB file\n",
    "        nwbfile = NWBFile(\n",
    "            session_description=session_description,\n",
    "            identifier = str(uuid4()),\n",
    "            session_start_time = sess_start,\n",
    "            lab=lab,\n",
    "            experimenter=meta.RanBy[i],\n",
    "            session_id = nwbfilename[0:-4], # check this\n",
    "        )\n",
    "\n",
    "        # add subject info\n",
    "        nwbfile.subject = Subject(\n",
    "            subject_id = meta.FocalID[i],\n",
    "            species = 'Microtus ochrogaster',\n",
    "            sex = meta.FocalSex[i],\n",
    "            genotype = meta.FocalGT[i]\n",
    "        )\n",
    "\n",
    "        # get assay duration\n",
    "        duration = float(meta.AssayDuration[i])\n",
    "\n",
    "        # figure out partner info\n",
    "        if meta.FocalSex[i]=='F':\n",
    "            pID = meta.MaleID[i]\n",
    "            pGT = meta.MaleGT[i]\n",
    "        elif meta.FocalSex[i]=='M':\n",
    "            pID = meta.FemaleID[i]\n",
    "            pGT = meta.MaleGT[i]\n",
    "        else:\n",
    "            print(f'Focal sex is neither F nor M; something is wrong with {ptag}.')\n",
    "\n",
    "        # Make lab metadata object lab metadata\n",
    "        if meta.AssayType[i]=='PPT':\n",
    "            sID = meta.StrangerID[i]\n",
    "            sGT = meta.StrangerGT[i]\n",
    "            lane = int(meta.PPTlane[i])\n",
    "            chamb = meta.PartnerChamber[i]\n",
    "            metaObj = make_metadata_object(meta.AssayType[i],False,float(meta.AssayDuration[i]),meta.AssayRoom[i],meta.Timeline[i],\n",
    "                                           meta.Ethogram[i],meta.RanBy[i],meta.FullTimeline[i],meta.FocalColor[i],pID,pGT,dpp.days,\n",
    "                                           sID=sID,sGT=sGT,lane=lane,chamber=chamb)\n",
    "        else:\n",
    "            metaObj = make_metadata_object(meta.AssayType[i],False,float(meta.AssayDuration[i]),meta.AssayRoom[i],meta.Timeline[i],\n",
    "                                           meta.Ethogram[i],meta.RanBy[i],meta.FullTimeline[i],meta.FocalColor[i],pID,pGT,dpp.days)\n",
    "\n",
    "        # Add the test LabMetaDataExtensionExample to the NWBFile\n",
    "        nwbfile.add_lab_meta_data(lab_meta_data=metaObj)\n",
    "\n",
    "        # Add video file\n",
    "        vid_path = os.path.join(meta.VideoPath[i],meta.VideoFile[i])\n",
    "        vid_rel_path = os.path.relpath(vid_path,nwbfile_path)\n",
    "        \n",
    "        video_ext_file = ImageSeries(\n",
    "            name='behaviorVideo',\n",
    "            description='Raw original video.',\n",
    "            unit='n.a.',\n",
    "            external_file=[vid_rel_path],\n",
    "            format='external',\n",
    "            starting_time=meta.VideoAssayStart[i],\n",
    "            rate=25.0,\n",
    "        )\n",
    "        \n",
    "        # add to NWB file\n",
    "        nwbfile.add_acquisition(video_ext_file)\n",
    "        \n",
    "        # get session specific audio data\n",
    "        if type(meta.AudioFile[i])==str: # check whether there is an audio file\n",
    "            aud_path = os.path.join(meta.AudioPath[i],meta.AudioFile[i])\n",
    "            rel_path = os.path.relpath(aud_path,nwbfile_path)\n",
    "            with wave.open(aud_path, \"rb\") as wave_file: # find sample rate\n",
    "                sampling_rate = wave_file.getframerate()\n",
    "            Fs = float(sampling_rate)\n",
    "\n",
    "            # set up acquisition object\n",
    "            aud_ext_file = ImageSeries( \n",
    "                name='behaviorAudio',\n",
    "                description='Raw freefield audio',\n",
    "                unit='n.a.',\n",
    "                external_file=[rel_path],\n",
    "                format='external',\n",
    "                starting_time=meta.AudioAssayStart[i],\n",
    "                rate=Fs,\n",
    "            )\n",
    "\n",
    "            # add to NWB file\n",
    "            nwbfile.add_acquisition(aud_ext_file)\n",
    "      \n",
    "        if i==12:\n",
    "            testfile = nwbfile\n",
    "        \n",
    "        # write file to disk\n",
    "        if write_NWB_to_disk:\n",
    "            with NWBHDF5IO(wfullpath, \"w\") as io:\n",
    "                io.write(nwbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f73cea17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nerissa\\AppData\\Local\\Temp\\ipykernel_2364\\2170868982.py:26: UserWarning: directory snippets already exists in your NWB path\n",
      "  warnings.warn(\"directory snippets already exists in your NWB path\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating snippet edges for ScnVoc17_day1...\n",
      "Writing snippets for ScnVoc17_day1...\n",
      "\n",
      "\n",
      "Calculating snippet edges for ScnVoc18_day1...\n",
      "Writing snippets for ScnVoc18_day1...\n",
      "\n",
      "\n",
      "Calculating snippet edges for ScnVoc19_day1...\n",
      "Writing snippets for ScnVoc19_day1...\n",
      "\n",
      "\n",
      "Calculating snippet edges for ScnVoc20_day1...\n",
      "Writing snippets for ScnVoc20_day1...\n",
      "\n",
      "\n",
      "Calculating snippet edges for ScnVoc21_day1...\n",
      "Writing snippets for ScnVoc21_day1...\n",
      "\n",
      "\n",
      "Calculating snippet edges for ScnVoc22_day1...\n",
      "Writing snippets for ScnVoc22_day1...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----- WRITE SNIPPET FILES -----\n",
    "\n",
    "alltags = meta.PairTag.to_list()\n",
    "\n",
    "# get all files\n",
    "allnwb = []\n",
    "# add all the file names except PPT files to a list\n",
    "allnwb += [each for each in os.listdir(nwbfile_path) if each.split('_')[0] in alltags]\n",
    "\n",
    "for i,fname in enumerate(allnwb):\n",
    "    # open file\n",
    "    io = NWBHDF5IO(os.path.join(nwbfile_path,fname), mode=\"r\") # <-- open in write to append snippets?\n",
    "    nwbfile = io.read()  \n",
    "    \n",
    "    # get audio path\n",
    "    \n",
    "    audrelpath = nwbfile.acquisition['behaviorAudio'].external_file[0]\n",
    "    audpath = os.path.normpath(os.path.join(nwbfile_path,audrelpath))\n",
    "    pathsplit = audpath.split('\\\\')\n",
    "    recstem = pathsplit[-1][:-4]\n",
    "    # check if snippet directory exists, and make a warning if it does\n",
    "    snipdir = os.path.join(nwbfile_path,'snippets')\n",
    "    if not os.path.isdir(snipdir):\n",
    "        os.makedirs(snipdir)\n",
    "    else:\n",
    "        warnings.warn(\"directory snippets already exists in your NWB path\")\n",
    "    # make data directory\n",
    "    datadir = os.path.join(snipdir,recstem)\n",
    "    if not os.path.isdir(datadir):\n",
    "        os.makedirs(datadir)\n",
    "        # write snippets\n",
    "        reclen = librosa.get_duration(filename=audpath)\n",
    "        print(f'Calculating snippet edges for {recstem}...')\n",
    "        starts,ends = snippets_from_whole_recording(winlen,overlap,reclen)\n",
    "        sample_rate, samples = wavfile.read(audpath)\n",
    "        print(f'Writing snippets for {recstem}...')\n",
    "        write_snippets_from_times(starts,ends,recstem,datadir,samples,sample_rate)\n",
    "        print('\\n')\n",
    "    else:\n",
    "        warnings.warn(f\"directory {recstem} already exists in snippets; not writing anything\")\n",
    "    # I want to extend the data spec to include intermediate processing stages, but right now I will just rely\n",
    "    # on the directories getting created in the right spot and infer them in later stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20fa0637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- WRITE VAK TOML FILES -----\n",
    "\n",
    "alltoml = [] # keep track of toml files for writing bat file\n",
    "\n",
    "for i,fname in enumerate(allnwb):\n",
    "    # open file\n",
    "    io = NWBHDF5IO(os.path.join(nwbfile_path,fname), mode=\"r\") # <-- open in write to append snippets?\n",
    "    nwbfile = io.read()\n",
    "    # get audio path\n",
    "    audrelpath = nwbfile.acquisition['behaviorAudio'].external_file[0]\n",
    "    audpath = os.path.normpath(os.path.join(nwbfile_path,audrelpath))\n",
    "    pathsplit = audpath.split('\\\\')\n",
    "    this_rec = pathsplit[-1][:-4]\n",
    "\n",
    "    # set up variables for writing toml\n",
    "    data_dir = os.path.join(nwbfile_path,'snippets',this_rec)\n",
    "    data_dir = str(data_dir).replace('\\\\','/')\n",
    "    output_dir = os.path.join(pred_path,this_rec)\n",
    "    if not os.path.isdir(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "    output_dir = str(output_dir).replace('\\\\','/')\n",
    "    annot_csv_filename = f'{this_rec}.annot.csv'\n",
    "    toml_name = f'{this_rec}-predict.toml'\n",
    "    alltoml.append(toml_name)\n",
    "\n",
    "    # write toml file\n",
    "    with open(os.path.join(analysis_path,toml_name),'w') as f:\n",
    "      f.write('[PREP]\\n')\n",
    "      f.write(f'data_dir = \\\"{data_dir}\\\"\\n')\n",
    "      f.write(f'output_dir = \\\"{output_dir}\\\"\\n')\n",
    "      f.write(f\"audio_format = \\\"{defaults['audio_format']}\\\"\\n\")\n",
    "      f.write('\\n')\n",
    "      f.write('[SPECT_PARAMS]\\n')\n",
    "      f.write(f\"fft_size = {defaults['fft_size']}\\n\")\n",
    "      f.write(f\"step_size = {defaults['step_size']}\\n\")\n",
    "      f.write('\\n')\n",
    "      f.write('[PREDICT]\\n')\n",
    "      f.write(f\"checkpoint_path = \\\"{defaults['checkpoint_path']}\\\"\\n\")\n",
    "      f.write(f\"labelmap_path = \\\"{defaults['labelmap_path']}\\\"\\n\")\n",
    "      f.write(f\"models = \\\"{defaults['models']}\\\"\\n\")\n",
    "      f.write(f\"batch_size = {defaults['batch_size']}\\n\")\n",
    "      f.write(f\"num_workers = {defaults['num_workers']}\\n\")\n",
    "      f.write(f\"device = \\\"{defaults['device']}\\\"\\n\")\n",
    "      f.write(f\"spect_scaler_path = \\\"{defaults['spect_scaler_path']}\\\"\\n\")\n",
    "      f.write(f'output_dir = \\\"{output_dir}\\\"\\n')\n",
    "      f.write(f'annot_csv_filename = \\\"{annot_csv_filename}\\\"\\n')\n",
    "      f.write(f\"majority_vote = {defaults['majority_vote']}\\n\")\n",
    "      f.write(f\"min_segment_dur = {defaults['min_segment_dur']}\\n\")\n",
    "      f.write('\\n')\n",
    "      f.write('[TweetyNet.optimizer]\\n')\n",
    "      f.write(f\"lr = {defaults['lr']}\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2487dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- WRITE BAT FILE WITH TOML COMMANDS -----\n",
    "bat_name = f'{cohort_tag}-predict.bat'\n",
    "with open(os.path.join(analysis_path,bat_name),'w') as f:\n",
    "    for toml in alltoml:\n",
    "        f.write(f\"vak prep {toml}\\n\")\n",
    "    for toml in alltoml:\n",
    "        f.write(f\"vak predict {toml}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0af9251e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging annotations for file ScnVoc17_introduction.nwb...\n",
      "Merging annotations for file ScnVoc18_introduction.nwb...\n",
      "Merging annotations for file ScnVoc19_introduction.nwb...\n",
      "Merging annotations for file ScnVoc20_introduction.nwb...\n",
      "Merging annotations for file ScnVoc21_introduction.nwb...\n",
      "Merging annotations for file ScnVoc22_introduction.nwb...\n"
     ]
    }
   ],
   "source": [
    "# ----- WRITE RAW OVERLAPS -----\n",
    "\n",
    "# get all files\n",
    "allnwb = []\n",
    "# add all the file names except PPT files to a list\n",
    "allnwb += [each for each in os.listdir(nwbfile_path) if each.split('_')[0] in alltags]\n",
    "\n",
    "for i,fname in enumerate(allnwb):\n",
    "    # open file\n",
    "    io = NWBHDF5IO(os.path.join(nwbfile_path,fname), mode=\"r+\") # <-- open in write to append snippets?\n",
    "    nwbfile = io.read()\n",
    "    # get audio path\n",
    "    audrelpath = nwbfile.acquisition['behaviorAudio'].external_file[0]\n",
    "    audpath = os.path.normpath(os.path.join(nwbfile_path,audrelpath))\n",
    "    pathsplit = audpath.split('\\\\')\n",
    "    recstem = pathsplit[-1][:-4]\n",
    "    vak_raw_path = os.path.join(pred_path,recstem)\n",
    "    vak_raw_file = f'{recstem}.annot.csv'\n",
    "    raven_file = f'{recstem}.raven.txt'\n",
    "    write_raven_from_annotation(vak_raw_path,vak_raw_file,vak_raw_path,raven_file)\n",
    "\n",
    "    # write new file with merged overlaps\n",
    "    merge_file = f'{recstem}.merged.raven.txt'\n",
    "    merge_window_overlaps(vak_raw_path,vak_raw_file,vak_raw_path,merge_file,minfreq,maxfreq)\n",
    "\n",
    "    # format merged overlaps to put in NWB\n",
    "    anno = pd.read_csv(os.path.join(vak_raw_path,merge_file),sep='\\t')\n",
    "    anno.rename(columns={'Begin Time (s)':'begin_time'}, inplace=True)\n",
    "    anno.rename(columns={'End Time (s)':'end_time'}, inplace=True)\n",
    "    anno.rename(columns={'Low Freq (Hz)':'low_freq'},inplace=True)\n",
    "    anno.rename(columns={'High Freq (Hz)':'high_freq'},inplace=True)\n",
    "    \n",
    "    if len(anno.begin_time)>0:\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            testforfield = nwbfile.intervals['calls_vak_rawmerge']\n",
    "            print(f'Field calls_vak_rawmerge already exists for file {fname}; moving on.')\n",
    "\n",
    "        except:\n",
    "            print(f'Merging annotations for file {fname}...')\n",
    "\n",
    "            call_intervals = TimeIntervals(\n",
    "            name=\"calls_vak_rawmerge\",\n",
    "            description=\"Intervals when a call was annotated; overlaps found and merged; no frequency information.\",\n",
    "            )\n",
    "\n",
    "            call_intervals.add_column(name=\"low_freq\", description=\"bottom of call box\")\n",
    "            call_intervals.add_column(name=\"high_freq\", description=\"top of call box\")\n",
    "\n",
    "            for i, start in enumerate(anno.begin_time):\n",
    "                end = anno.end_time[i]\n",
    "                lowf = anno.low_freq[i]\n",
    "                highf = anno.high_freq[i]\n",
    "                call_intervals.add_row(start_time=start,stop_time=end,low_freq=lowf,high_freq=highf)\n",
    "\n",
    "            # write call annotation object to NWB file\n",
    "            nwbfile.add_time_intervals(call_intervals)\n",
    "            io.write(nwbfile)\n",
    "        \n",
    "    else:\n",
    "        print(f'No annotations for file {merge_file}; moving on.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c690f26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming and adjusting annotations for ScnVoc17_day1...\n",
      "Went from 7689 annotations to 7264 annotations.\n",
      "Trimming and adjusting annotations for ScnVoc18_day1...\n",
      "Went from 5975 annotations to 5797 annotations.\n",
      "Trimming and adjusting annotations for ScnVoc19_day1...\n",
      "Went from 703 annotations to 439 annotations.\n",
      "Trimming and adjusting annotations for ScnVoc20_day1...\n",
      "Went from 3064 annotations to 2736 annotations.\n",
      "Trimming and adjusting annotations for ScnVoc21_day1...\n",
      "Went from 2494 annotations to 2214 annotations.\n",
      "Trimming and adjusting annotations for ScnVoc22_day1...\n",
      "Went from 4906 annotations to 4730 annotations.\n"
     ]
    }
   ],
   "source": [
    "# ----- ADD TIME BASED FILTERING TO PIPELINE -----\n",
    "\n",
    "assay_len = 1800\n",
    "\n",
    "for i,fname in enumerate(allnwb):\n",
    "    # open file\n",
    "    io = NWBHDF5IO(os.path.join(nwbfile_path,fname), mode=\"r+\") # <-- open in write to append snippets?\n",
    "    nwbfile = io.read()\n",
    "    \n",
    "    # get audio path\n",
    "    audrelpath = nwbfile.acquisition['behaviorAudio'].external_file[0]\n",
    "    audpath = os.path.normpath(os.path.join(nwbfile_path,audrelpath))\n",
    "    pathsplit = audpath.split('\\\\')\n",
    "    recstem = pathsplit[-1][:-4]\n",
    "       \n",
    "    sts = nwbfile.acquisition['behaviorAudio'].starting_time\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        testforfield = nwbfile.intervals['calls_assay_time']\n",
    "        print(f'Field calls_assay_time already exists for file {fname}; moving on.')\n",
    "\n",
    "    except:\n",
    "        print(f'Trimming and adjusting annotations for {recstem}...')\n",
    "\n",
    "        # load up annotation times from NWB file\n",
    "        raw_starts = nwbfile.intervals['calls_vak_rawmerge'].start_time[:]\n",
    "        raw_ends = nwbfile.intervals['calls_vak_rawmerge'].stop_time[:]\n",
    "        raw_high = nwbfile.intervals['calls_vak_rawmerge'].high_freq[:]\n",
    "        raw_low = nwbfile.intervals['calls_vak_rawmerge'].low_freq[:]\n",
    "\n",
    "        # adjust times to fit within analysis window\n",
    "        adj_starts = raw_starts[np.logical_and(raw_starts>sts,raw_ends<(sts+assay_len))] - sts\n",
    "        adj_ends = raw_ends[np.logical_and(raw_starts>sts,raw_ends<(sts+assay_len))] - sts\n",
    "\n",
    "        print(f'Went from {raw_starts.size} annotations to {adj_starts.size} annotations.')\n",
    "\n",
    "        call_intervals = TimeIntervals(\n",
    "        name=\"calls_assay_time\",\n",
    "        description='Call intervals; overlaps merged; no freq info; adjusted to fit in assay time.')\n",
    "\n",
    "        call_intervals.add_column(name=\"low_freq\", description=\"bottom of call box\")\n",
    "        call_intervals.add_column(name=\"high_freq\", description=\"top of call box\")\n",
    "\n",
    "        for i, start in enumerate(adj_starts):\n",
    "            end = adj_ends[i]\n",
    "            lowf = raw_low[i]\n",
    "            highf = raw_high[i]\n",
    "            call_intervals.add_row(start_time=start,stop_time=end,low_freq=lowf,high_freq=highf)\n",
    "\n",
    "        # write call annotation object to NWB file\n",
    "        nwbfile.add_time_intervals(call_intervals)\n",
    "        io.write(nwbfile)\n",
    "\n",
    "        io.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84184b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running contour extractions and stats for ScnVoc17_day1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nerissa\\anaconda3\\envs\\voc230824\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running contour extractions and stats for ScnVoc18_day1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nerissa\\anaconda3\\envs\\voc230824\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Nerissa\\anaconda3\\envs\\voc230824\\lib\\site-packages\\scipy\\signal\\_signaltools.py:1625: RuntimeWarning: divide by zero encountered in divide\n",
      "  res *= (1 - noise / lVar)\n",
      "C:\\Users\\Nerissa\\anaconda3\\envs\\voc230824\\lib\\site-packages\\scipy\\signal\\_signaltools.py:1625: RuntimeWarning: invalid value encountered in multiply\n",
      "  res *= (1 - noise / lVar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running contour extractions and stats for ScnVoc19_day1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nerissa\\anaconda3\\envs\\voc230824\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running contour extractions and stats for ScnVoc20_day1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nerissa\\anaconda3\\envs\\voc230824\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running contour extractions and stats for ScnVoc21_day1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nerissa\\anaconda3\\envs\\voc230824\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running contour extractions and stats for ScnVoc22_day1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nerissa\\anaconda3\\envs\\voc230824\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Nerissa\\anaconda3\\envs\\voc230824\\lib\\site-packages\\scipy\\signal\\_signaltools.py:1625: RuntimeWarning: divide by zero encountered in divide\n",
      "  res *= (1 - noise / lVar)\n",
      "C:\\Users\\Nerissa\\anaconda3\\envs\\voc230824\\lib\\site-packages\\scipy\\signal\\_signaltools.py:1625: RuntimeWarning: invalid value encountered in multiply\n",
      "  res *= (1 - noise / lVar)\n"
     ]
    }
   ],
   "source": [
    "# ----- RUN CONTOUR FREQUENCY STATS CALCULATIONS AND ADD TO NWB FILES -----\n",
    "\n",
    "# no 5 ms merge for Scn2a?\n",
    "use_annos = 'calls_vak_rawmerge'\n",
    "\n",
    "for i,fname in enumerate(allnwb):\n",
    "\n",
    "    # open file\n",
    "    io = NWBHDF5IO(os.path.join(nwbfile_path,fname), mode=\"r+\") # <-- open in write to append snippets?\n",
    "    nwbfile = io.read()\n",
    "    \n",
    "    # get audio path\n",
    "    audrelpath = nwbfile.acquisition['behaviorAudio'].external_file[0]\n",
    "    audpath = os.path.normpath(os.path.join(nwbfile_path,audrelpath))\n",
    "    pathsplit = audpath.split('\\\\')\n",
    "    recstem = pathsplit[-1][:-4]\n",
    "    \n",
    "    print(f'Running contour extractions and stats for {recstem}...')\n",
    "    \n",
    "    sts = nwbfile.acquisition['behaviorAudio'].starting_time\n",
    "\n",
    "    # load up annotation times from NWB file\n",
    "    starts = nwbfile.intervals[use_annos].start_time[:]\n",
    "    ends = nwbfile.intervals[use_annos].stop_time[:]\n",
    "    \n",
    "    # load up audio data\n",
    "    fs, auddat = wav.read(audpath)\n",
    "    \n",
    "    # generate snippets to work on\n",
    "    allsnips = generate_all_snippets(fs,auddat,starts,ends,spad,epad)\n",
    "\n",
    "    # set up data storage table\n",
    "    nrcalls = len(allsnips)\n",
    "    nrstats = len(allstats)\n",
    "    alldat = nanarray(nrcalls,nrstats)\n",
    "    \n",
    "    # loop over snippets and do calculations\n",
    "    for i,snip in enumerate(allsnips):\n",
    "\n",
    "        # log start and end times in the table\n",
    "        alldat[i,1] = starts[i]\n",
    "        alldat[i,2] = ends[i]-starts[i]\n",
    "\n",
    "        # calculate spectrogram and contours\n",
    "        usecall,spec,contx,conty,f0,frqbands,tmax,ftmax = frequency_process_call(snip,fs,psdwin,NFFT,noverl,fmin,fmax,pwrmin,prominence_factor,rel_height_param,\n",
    "                                                  mel_nfft,n_mels,mel_winlen,wiener_kernel,mf,fr,it,grndmeanfac) # add f0 to table\n",
    "        \n",
    "        # if the call is not a false positive, extract stats based on generated contours\n",
    "        if usecall:\n",
    "            flatx,flaty = flatten_contours_across_bands(contx,conty)\n",
    "            line = get_frequency_stats_from_contours(flatx,flaty,fs,mel_winlen,mel_nfft,tmax,ftmax)\n",
    "            alldat[i,0] = line[0,0]\n",
    "            alldat[i,3] = f0\n",
    "            alldat[i,4] = frqbands\n",
    "            alldat[i,5:] = line[0,1:]\n",
    "\n",
    "        else:\n",
    "            alldat[i,0] = False\n",
    "            \n",
    "    # save calculations to NWB file\n",
    "    \n",
    "    # convert to dataframe\n",
    "    df = pd.DataFrame(data=alldat,columns=allstats)\n",
    "    \n",
    "    # log unfiltered version\n",
    "    unfiltered_freq_stats = TimeIntervals(\n",
    "    name=\"freq_stats_unfiltered\",\n",
    "    description='Frequency stats for merged calls with no assay time adjustments or filtering of false positives.')\n",
    "\n",
    "    unfiltered_freq_stats.add_column(name=allstats[0],description=descriptions[0])\n",
    "    for i,statname in enumerate(allstats[2:]):\n",
    "        desc = descriptions[i+2]\n",
    "        unfiltered_freq_stats.add_column(name=statname,description=desc)    \n",
    "\n",
    "\n",
    "    unfiltered_freq_stats = add_frequency_data_to_NWBintervals(df,unfiltered_freq_stats)     \n",
    "    nwbfile.add_time_intervals(unfiltered_freq_stats)\n",
    "\n",
    "    # log time adjusted version\n",
    "\n",
    "    dfct = df.copy()\n",
    "    dfct.startTime = dfct.startTime - sts\n",
    "\n",
    "    # initialize NWB object\n",
    "    timeadj_freq_stats = TimeIntervals(\n",
    "    name=\"freq_stats_timeAdj\",\n",
    "    description='Frequency stats for merged calls with assay time adjustments but no calls removed.')\n",
    "\n",
    "    # build out columns\n",
    "    timeadj_freq_stats.add_column(name=allstats[0],description=descriptions[0])\n",
    "    for i,statname in enumerate(allstats[2:]):\n",
    "        desc = descriptions[i+2]\n",
    "        timeadj_freq_stats.add_column(name=statname,description=desc)\n",
    "\n",
    "    # add data   \n",
    "    timeadj_freq_stats = add_frequency_data_to_NWBintervals(dfct,timeadj_freq_stats)   \n",
    "    nwbfile.add_time_intervals(timeadj_freq_stats)\n",
    "\n",
    "    # make a version with false positives and excess times filtered out\n",
    "    dfctfilt = dfct.loc[(dfct['startTime']>0) & (dfct['startTime']<assay_len) & (dfct['callBool']==True)]\n",
    "\n",
    "    # initialize NWB object\n",
    "    filt_freq_stats = TimeIntervals(\n",
    "    name=\"freq_stats_filtered\",\n",
    "    description='Frequency stats for merged calls by assay time and with false positives and out of bounds calls removed.')\n",
    "\n",
    "    # build out columns\n",
    "    filt_freq_stats.add_column(name=allstats[0],description=descriptions[0])\n",
    "    for i,statname in enumerate(allstats[2:]):\n",
    "        desc = descriptions[i+2]\n",
    "        filt_freq_stats.add_column(name=statname,description=desc)\n",
    "\n",
    "    # add data\n",
    "    filt_freq_stats = add_frequency_data_to_NWBintervals(dfctfilt,filt_freq_stats)\n",
    "    nwbfile.add_time_intervals(filt_freq_stats)\n",
    "    \n",
    "    io.write(nwbfile)\n",
    "    io.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c251d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
